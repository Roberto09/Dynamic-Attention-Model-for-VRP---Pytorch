{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import torch\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from attention_dynamic_model import AttentionDynamicModel, set_decode_type\n",
    "from reinforce_baseline import RolloutBaseline\n",
    "from train import train_model\n",
    "\n",
    "from utils import create_data_on_disk, get_cur_time\n",
    "\n",
    "# Params of model\n",
    "SAMPLES = 1280000 # 1024*1250\n",
    "BATCH = 1024\n",
    "START_EPOCH = 0\n",
    "END_EPOCH = 40\n",
    "SKIP_WARMUP = False\n",
    "embedding_dim = 128\n",
    "LEARNING_RATE = 0.0001\n",
    "ROLLOUT_SAMPLES = 10000\n",
    "NUMBER_OF_WP_EPOCHS = 1\n",
    "GRAD_NORM_CLIPPING = 1.0\n",
    "BATCH_VERBOSE = 625\n",
    "VAL_BATCH_SIZE = 1000\n",
    "VALIDATE_SET_SIZE = 10000\n",
    "SEED = 1234\n",
    "GRAPH_SIZE = 20\n",
    "FILENAME = 'VRP_{}_{}'.format(GRAPH_SIZE, strftime(\"%Y-%m-%d\", gmtime()))\n",
    "\n",
    "# Initialize model\n",
    "model_torch = AttentionDynamicModel(embedding_dim).cuda()\n",
    "set_decode_type(model_torch, \"sampling\")\n",
    "print(get_cur_time(), 'model initialized')\n",
    "\n",
    "# Create and save validation dataset\n",
    "validation_dataset = create_data_on_disk(GRAPH_SIZE,\n",
    "                                         VALIDATE_SET_SIZE,\n",
    "                                         is_save=True,\n",
    "                                         filename=FILENAME,\n",
    "                                         is_return=True,\n",
    "                                         seed = SEED)\n",
    "print(get_cur_time(), 'validation dataset created and saved on the disk')\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = torch.optim.Adam(params=model_pt.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Initialize baseline\n",
    "baseline = RolloutBaseline(model_torch,\n",
    "                           wp_n_epochs = NUMBER_OF_WP_EPOCHS,\n",
    "                           epoch = 0,\n",
    "                           num_samples=ROLLOUT_SAMPLES)\n",
    "print(get_cur_time(), 'baseline initialized')\n",
    "\n",
    "train_model(optimizer,\n",
    "            model_torch,\n",
    "            baseline,\n",
    "            validation_dataset,\n",
    "            samples = SAMPLES,\n",
    "            batch = BATCH,\n",
    "            val_batch_size = VAL_BATCH_SIZE,\n",
    "            start_epoch = START_EPOCH,\n",
    "            end_epoch = END_EPOCH,\n",
    "            skip_warmup = SKIP_WARMUP,\n",
    "            grad_norm_clipping = GRAD_NORM_CLIPPING,\n",
    "            batch_verbose = BATCH_VERBOSE,\n",
    "            graph_size = GRAPH_SIZE,\n",
    "            filename = FILENAME\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
