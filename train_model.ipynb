{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from attention_dynamic_model import AttentionDynamicModel, set_decode_type\n",
    "from reinforce_baseline import RolloutBaseline\n",
    "from train import train_model\n",
    "\n",
    "from time import strftime, gmtime\n",
    "from utils import create_data_on_disk, get_cur_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params of model\n",
    "SAMPLES = 512 # 128*10000\n",
    "BATCH = 128\n",
    "START_EPOCH = 0\n",
    "END_EPOCH = 5\n",
    "FROM_CHECKPOINT = False\n",
    "embedding_dim = 128\n",
    "LEARNING_RATE = 0.0001\n",
    "ROLLOUT_SAMPLES = 10000\n",
    "NUMBER_OF_WP_EPOCHS = 1\n",
    "GRAD_NORM_CLIPPING = 1.0\n",
    "BATCH_VERBOSE = 1000\n",
    "VAL_BATCH_SIZE = 1000\n",
    "VALIDATE_SET_SIZE = 10000\n",
    "SEED = 1234\n",
    "GRAPH_SIZE = 50\n",
    "FILENAME = 'VRP_{}_{}'.format(GRAPH_SIZE, strftime(\"%Y-%m-%d\", gmtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model_pt = AttentionDynamicModel(embedding_dim)\n",
    "set_decode_type(model_pt, \"sampling\")\n",
    "print(get_cur_time(), 'model initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save validation dataset\n",
    "validation_dataset = create_data_on_disk(GRAPH_SIZE,\n",
    "                                         VALIDATE_SET_SIZE,\n",
    "                                         is_save=True,\n",
    "                                         filename=FILENAME,\n",
    "                                         is_return=True,\n",
    "                                         seed = SEED)\n",
    "print(get_cur_time(), 'validation dataset created and saved on the disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize optimizer\n",
    "optimizer = torch.optim.Adam(params=model_pt.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize baseline\n",
    "baseline = RolloutBaseline(model_pt,\n",
    "                           wp_n_epochs = NUMBER_OF_WP_EPOCHS,\n",
    "                           epoch = 0,\n",
    "                           num_samples=ROLLOUT_SAMPLES,\n",
    "                           filename = FILENAME,\n",
    "                           from_checkpoint = FROM_CHECKPOINT,\n",
    "                           embedding_dim=embedding_dim,\n",
    "                           graph_size=GRAPH_SIZE\n",
    "                           )\n",
    "print(get_cur_time(), 'baseline initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
